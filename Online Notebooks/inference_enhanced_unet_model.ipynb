{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQNy5qD8I6HI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class EnhancedUNet(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=1, base_channels=32):\n",
        "        super(EnhancedUNet, self).__init__()\n",
        "\n",
        "        self.enc1 = self._conv_block(in_channels, base_channels)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc2 = self._conv_block(base_channels, base_channels * 2)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.enc3 = self._conv_block(base_channels * 2, base_channels * 4)\n",
        "        self.pool3 = nn.MaxPool2d(2)\n",
        "\n",
        "        self.bottleneck = self._conv_block(base_channels * 4, base_channels * 8)\n",
        "\n",
        "        self.up3 = nn.ConvTranspose2d(base_channels * 8, base_channels * 4, kernel_size=2, stride=2)\n",
        "        self.dec3 = self._conv_block(base_channels * 8, base_channels * 4)\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(base_channels * 4, base_channels * 2, kernel_size=2, stride=2)\n",
        "        self.dec2 = self._conv_block(base_channels * 4, base_channels * 2)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(base_channels * 2, base_channels, kernel_size=2, stride=2)\n",
        "        self.dec1 = self._conv_block(base_channels * 2, base_channels)\n",
        "\n",
        "        self.final = nn.Conv2d(base_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def _conv_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(0.1),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool1(e1))\n",
        "        e3 = self.enc3(self.pool2(e2))\n",
        "\n",
        "        b = self.bottleneck(self.pool3(e3))\n",
        "\n",
        "        d3 = self.up3(b)\n",
        "        d3 = torch.cat([e3, d3], dim=1)\n",
        "        d3 = self.dec3(d3)\n",
        "\n",
        "        d2 = self.up2(d3)\n",
        "        d2 = torch.cat([e2, d2], dim=1)\n",
        "        d2 = self.dec2(d2)\n",
        "\n",
        "        d1 = self.up1(d2)\n",
        "        d1 = torch.cat([e1, d1], dim=1)\n",
        "        d1 = self.dec1(d1)\n",
        "\n",
        "        return self.final(d1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eu8BHwreJA7-"
      },
      "outputs": [],
      "source": [
        "# Cell 2: Inference and Visualization Function\n",
        "\n",
        "def run_inference(img_path, mask_path, slice_idx, model_path):\n",
        "    \"\"\"\n",
        "    Loads the trained model, performs inference on a single CT slice,\n",
        "    and plots the original image, ground truth, and model prediction.\n",
        "    \"\"\"\n",
        "    # Device configuration (use GPU if available)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Running inference on: {device}\")\n",
        "\n",
        "    # Initialize the model and load pre-trained weights\n",
        "    model = EnhancedUNet(in_channels=1, out_channels=1).to(device)\n",
        "    checkpoint = torch.load(model_path, map_location=device)\n",
        "\n",
        "    # Handle both dictionary-based and raw state_dict checkpoints\n",
        "    if 'model_state_dict' in checkpoint:\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        model.load_state_dict(checkpoint)\n",
        "\n",
        "    # Set model to evaluation mode (disables Dropout and fixes BatchNorm)\n",
        "    model.eval()\n",
        "\n",
        "    # Load image and ground truth mask data\n",
        "    img_data = nib.load(img_path).dataobj[:, :, slice_idx]\n",
        "    mask_data = nib.load(mask_path).dataobj[:, :, slice_idx]\n",
        "\n",
        "    # Preprocessing: Windowing (-200 to 250 HU), Normalization, and Resizing\n",
        "    img_clipped = np.clip(img_data, -200, 250)\n",
        "    img_norm = (img_clipped - (-200)) / 450.0\n",
        "    img_resized = cv2.resize(img_norm, (256, 256), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    # Prepare binary ground truth mask (mask > 0 includes Liver + Tumor)\n",
        "    true_mask = cv2.resize((mask_data > 0).astype(np.float32), (256, 256), interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "    # Convert image to PyTorch tensor format: (Batch, Channel, Height, Width)\n",
        "    img_tensor = torch.tensor(img_resized, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "    # Perform prediction without tracking gradients (saves memory & speeds up)\n",
        "    with torch.no_grad():\n",
        "        output_logit = model(img_tensor)\n",
        "        pred_prob = torch.sigmoid(output_logit).squeeze().cpu().numpy()\n",
        "        pred_mask = (pred_prob > 0.5).astype(np.uint8)\n",
        "\n",
        "    # Visualization\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    # Plot 1: Original CT Scan\n",
        "    axes[0].imshow(img_resized, cmap='gray')\n",
        "    axes[0].set_title(f'Original CT Scan (Slice {slice_idx})')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    # Plot 2: Ground Truth\n",
        "    axes[1].imshow(img_resized, cmap='gray')\n",
        "    axes[1].imshow(true_mask, cmap='Greens', alpha=0.5)\n",
        "    axes[1].set_title('Ground Truth (Green)')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    # Plot 3: Model Prediction\n",
        "    axes[2].imshow(img_resized, cmap='gray')\n",
        "    axes[2].imshow(pred_mask, cmap='Reds', alpha=0.5)\n",
        "    axes[2].set_title('Model Prediction (Red)')\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "run_inference(\n",
        "    img_path='path/to/volume-XX.nii',\n",
        "    mask_path='path/to/segmentation-XX.nii',\n",
        "    slice_idx=150,\n",
        "    model_path='best_model.pth'\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
